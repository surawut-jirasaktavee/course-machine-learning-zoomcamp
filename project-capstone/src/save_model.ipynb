{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387adaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f594734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 06:18:10.805384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-18 06:18:10.805416: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-18 06:18:10.805442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-21-87): /proc/driver/nvidia/version does not exist\n",
      "2022-12-18 06:18:10.805674: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./models/xception_final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157b7cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-18 06:20:58--  https://datasets-server.huggingface.co/assets/beans/--/default/test/9/image/image.jpg\n",
      "Resolving datasets-server.huggingface.co (datasets-server.huggingface.co)... 54.159.171.62, 34.226.254.71, 35.169.19.193, ...\n",
      "Connecting to datasets-server.huggingface.co (datasets-server.huggingface.co)|54.159.171.62|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68494 (67K) [image/jpeg]\n",
      "Saving to: ‘angular_leaf_spot.jpg’\n",
      "\n",
      "angular_leaf_spot.j 100%[===================>]  66.89K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-12-18 06:20:59 (539 KB/s) - ‘angular_leaf_spot.jpg’ saved [68494/68494]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://datasets-server.huggingface.co/assets/beans/--/default/test/9/image/image.jpg -O angular_leaf_spot.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76543cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"./angular_leaf_spot.jpg\"\n",
    "img = load_img(img_path, target_size=(299, 299))\n",
    "\n",
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02e3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"angular_leaf_spot\",\n",
    "    \"bean_rust\",\n",
    "    \"healthy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd39a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fef8847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angular_leaf_spot'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(dict(zip(classes, np.abs(pred[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d88837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f2dbd95c520>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf8e920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 06:22:28.639130: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: beans-model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'beans-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f06abfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angular_leaf_spot.jpg  beans-model  models  notebook.ipynb  save_model.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bfc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
